## kubeadm 部署 kubernetes

### ※ 软硬件要求

| Rocky8.10  | `https://download.rockylinux.org/pub/rocky/8/isos/x86_64/Rocky-8.10-x86_64-dvd1.iso` |      |
| ---------- | ------------------------------------------------------------ | ---- |
| K8S-Master | 192.168.0.105                                                |      |
| K8S-Works  | 192.168.0.106                                                |      |
| kubeadm    | vsersion--1.31.4                                             |      |
| kubelet    | vsersion--1.31.4                                             |      |
| kubectl    | vsersion--1.31.4                                             |      |

**修改主机名称**

```bash
hostnamectl set-hostname K8S-Master
hostnamectl set-hostname K8S-Works
```

### 1.基础环境搭建

```bash
systemctl disable --now firewalld
systemctl disable --now dnsmasq

setenforce 0
sed -i 's#SELINUX=enforcing#SELINUX=disabled#g' /etc/sysconfig/selinux
sed -i 's#SELINUX=enforcing#SELINUX=disabled#g' /etc/selinux/config

swapoff -a && sysctl -w vm.swappiness=0
sed -ri '/^[^#]*swap/s@^@#@' /etc/fstab

sed -e 's|^mirrorlist=|#mirrorlist=|g' \
    -e 's|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.aliyun.com/rockylinux|g' \
    -i.bak \
    /etc/yum.repos.d/Rocky-*.repo
dnf makecache

# -e 's|^mirrorlist=|#mirrorlist=|g'：注释掉所有 mirrorlist 行。
# -e 's|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.aliyun.com/rockylinux|g'：取消注释并替换 baseurl 地址为阿里云镜像源地址。
# -i.bak：对文件进行原地修改，同时备份 .bak 文件。

yum install wget jq psmisc vim net-tools telnet yum-utils device-mapper-persistent-data lvm2 git -y

#注意版本号的更换，需要安装什么版本的k8s，按照实际情况进行修改即可
cat > /etc/yum.repos.d/kubernetes.repo <<EOF
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.31/rpm/
enabled=1
gpgcheck=1
gpgkey=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.31/rpm/repodata/repomd.xml.key
EOF

yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
```

### 2.安装containerd

```bash
yum install containerd.io -y
cat > /etc/modules-load.d/containerd.conf <<EOF
overlay
br_netfilter
EOF

sudo modprobe overlay
sudo modprobe br_netfilter

cat > /etc/sysctl.d/99-kubernetes-cri.conf <<EOF
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
net.bridge.bridge-nf-call-ip6tables = 1
EOF
sudo sysctl --system

sudo mkdir -p /etc/containerd
containerd config default | sudo cat > /etc/containerd/config.toml

sed -i 's#SystemdCgroup = false#SystemdCgroup =true#g' /etc/containerd/config.toml
sed -i 's#k8s.gcr.io/pause#registry.cn-hangzhou.aliyuncs.com/google_containers/pause#g' /etc/containerd/config.toml
sed -i 's#registry.gcr.io/pause#registry.cn-hangzhou.aliyuncs.com/google_containers/pause#g' /etc/containerd/config.toml
sed -i 's#registry.k8s.io/pause#registry.cn-hangzhou.aliyuncs.com/google_containers/pause#g' /etc/containerd/config.toml

# 启动Containerd
systemctl daemon-reload
systemctl enable --now containerd
```

### 3.💩安装kubeadm

```bash
yum install kubeadm-1.31.* kubelet-1.31.* kubectl-1.31.* -y
systemctl enable --now kubelet

# 下载镜像
kubeadm config images pull --image-repository registry.cn-hangzhou.aliyuncs.com/google_containers --kubernetes-version 1.31.4

[root@localhost ~]# kubeadm config images pull \
> --image-repository registry.cn-hangzhou.aliyuncs.com/google_containers --kubernetes-version 1.31.4
[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.31.4
[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.31.4
[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.31.4
[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.31.4
[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:v1.11.3
[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.10
[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.5.15-0
```

![image-20250105224236996](./images/1.kubeadm%E9%83%A8%E7%BD%B2/image-20250105224236996.png)

#### 3.1 Master节点初始化

```bash
kubeadm init --apiserver-advertise-address 192.168.0.105 --image-repository registry.cn-hangzhou.aliyuncs.com/google_containers --cri-socket "unix:///var/run/containerd/containerd.sock" --kubernetes-version 1.31.4 
# 版本需要替换为实际版本号


Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

Alternatively, if you are the root user, you can run:

  export KUBECONFIG=/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 192.168.0.105:6443 --token su6wcn.5qw19ib5lc9vb3xm \
	--discovery-token-ca-cert-hash sha256:c7d4d20d51f4cc24d8745c3561f40d060ba31d1bb205c9b4f02923b7457aadde 

```

#### 3.2 Work节点加入集群

```bash
kubeadm join 192.168.0.105:6443 --token su6wcn.5qw19ib5lc9vb3xm \
	--discovery-token-ca-cert-hash sha256:c7d4d20d51f4cc24d8745c3561f40d060ba31d1bb205c9b4f02923b7457aadde
```

#### 3.3 为Master节点配置kubectl

```bash
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
```

#### 3.4 安装Addons 安装

```bash
git clone https://gitee.com/dukuan/k8s-ha-install.git
cd k8s-ha-install
kubectl create -f calico.yaml
kubectl create -f krm.yaml
```

#### 3.5 查看集群

```bash
[root@K8S-Master k8s-ha-install]# kubectl get node -owide
NAME         STATUS   ROLES           AGE   VERSION   INTERNAL-IP     EXTERNAL-IP   OS-IMAGE                            KERNEL-VERSION             CONTAINER-RUNTIME
k8s-master   Ready    control-plane   32h   v1.31.4   192.168.0.105   <none>        Rocky Linux 8.10 (Green Obsidian)   4.18.0-553.el8_10.x86_64   containerd://1.6.32
k8s-works    Ready    <none>          32h   v1.31.4   192.168.0.106   <none>        Rocky Linux 8.10 (Green Obsidian)   4.18.0-553.el8_10.x86_64   containerd://1.6.32
```

### 4.🚀集群扩容

#### 关键说明

1. **Worker 节点**：直接使用普通 `kubeadm join` 命令。
2. **Master 节点**：必须加 `--control-plane --certificate-key` 参数。
3. **端口开放**：确保所有节点能访问 Master 的 `6443` 端口。

#### 4.1 Worker 节点加入

1. 生成新的 Token（在现有 Master 节点执行）

```bash
# 生成新 Token（有效期默认24小时）
kubeadm token create --print-join-command
kubeadm join 192.168.0.105:6443 --token wzi8kz.ig2xfa11393fm19a --discovery-token-ca-cert-hash sha256:c7d4d20d51f4cc24d8745c3561f40d060ba31d1bb205c9b4f02923b7457aadde 
```

2. 在 Worker 节点执行上述命令

```bash
kubeadm join 192.168.0.105:6443 --token wzi8kz.ig2xfa11393fm19a --discovery-token-ca-cert-hash sha256:c7d4d20d51f4cc24d8745c3561f40d060ba31d1bb205c9b4f02923b7457aadde 
```

------

#### 4.2 Master 节点加入

1. 生成证书密钥（在现有 Master 节点执行）

```bash
# 生成新的证书密钥（用于签发新 Master 的证书）
kubeadm init phase upload-certs --upload-certs

W0313 23:31:20.843675  151933 version.go:109] could not fetch a Kubernetes version from the internet: unable to get URL "https://dl.k8s.io/release/stable-1.txt": Get "https://cdn.dl.k8s.io/release/stable-1.txt": dial tcp 146.75.113.55:443: i/o timeout (Client.Timeout exceeded while awaiting headers)
W0313 23:31:20.843849  151933 version.go:110] falling back to the local client version: v1.31.4
[upload-certs] Storing the certificates in Secret "kubeadm-certs" in the "kube-system" Namespace
[upload-certs] Using certificate key:
c41bd7777ca63bad307a468e99871fdbdf9bdd2ef3fb9d00b35e02d39d8d827e
```

2. 生成 Master 节点的完整 Join 命令

```bash
# 生成包含证书密钥的 Join 命令（有效期2小时）
kubeadm token create --certificate-key <上一步的证书密钥> --print-join-command

kubeadm token create --certificate-key c41bd7777ca63bad307a468e99871fdbdf9bdd2ef3fb9d00b35e02d39d8d827e --print-join-command
kubeadm join 192.168.0.105:6443 --token xhq1z2.5jsq35embtahsa7e --discovery-token-ca-cert-hash sha256:c7d4d20d51f4cc24d8745c3561f40d060ba31d1bb205c9b4f02923b7457aadde --control-plane --certificate-key c41bd7777ca63bad307a468e99871fdbdf9bdd2ef3fb9d00b35e02d39d8d827e
```

3. 在新 Master 节点执行上述命令

```bash
kubeadm join 192.168.0.105:6443 \
	--token xhq1z2.5jsq35embtahsa7e \
	--discovery-token-ca-cert-hash sha256:c7d4d20d51f4cc24d8745c3561f40d060ba31d1bb205c9b4f02923b7457aadde \
	--control-plane \
	--certificate-key c41bd7777ca63bad307a468e99871fdbdf9bdd2ef3fb9d00b35e02d39d8d827e
```

### FAQ:

#### 1.Master 节点扩容失败

```bash
[root@K8S-Master-2 ~]# kubeadm join 192.168.0.105:6443 --token w30l7l.zsuh67t66bjgy2vs --discovery-token-ca-cert-hash sha256:c7d4d20d51f4cc24d8745c3561f40d060ba31d1bb205c9b4f02923b7457aadde --control-plane --certificate-key c41bd7777ca63bad307a468e99871fdbdf9bdd2ef3fb9d00b35e02d39d8d827e
[preflight] Running pre-flight checks
	[WARNING FileExisting-tc]: tc not found in system path

	[WARNING Hostname]: hostname "k8s-master-2" could not be reached
	[WARNING Hostname]: hostname "k8s-master-2": lookup k8s-master-2 on 8.8.8.8:53: no such host
[preflight] Reading configuration from the cluster...
[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml'
error execution phase preflight: 
One or more conditions for hosting a new control plane instance is not satisfied.

unable to add a new control plane instance to a cluster that doesn't have a stable controlPlaneEndpoint address

Please ensure that:
* The cluster has a stable controlPlaneEndpoint address.
* The certificates that must be shared among control plane instances are provided.


To see the stack trace of this error execute with --v=5 or higher

```

**原因：**

1. 缺少 controlPlaneEndpoint
   - 当初始化集群时，若未通过 `--control-plane-endpoint` 指定负载均衡器地址（如 HAProxy、云厂商 LB），kubeadm 默认使用单个 Master 节点的 IP（如 `192.168.0.105`）。
   - 当尝试添加第二个 Master 节点时，集群无法识别多 Master 的入口，导致报错。
2. 主机名解析问题
   - 错误提示 `lookup k8s-master-2 on 114.114.114.114:53: no such host` 表明新 Master 节点的主机名无法通过 DNS 解析。
   - Kubernetes 依赖节点主机名的正向和反向解析，若未配置本地 DNS 或 `/etc/hosts`，会导致通信失败。



```bash
#备份当前 kubeadm 配置
kubectl -n kube-system get cm kubeadm-config -o yaml > kubeadm-config-backup.yaml

#编辑配置，在ClusterConfiguration字段内添加 controlPlaneEndpoint
kubectl -n kube-system edit cm kubeadm-config
    controlPlaneEndpoint: "192.168.0.40:6443"
```

更新证书

```bash
# 删除旧证书
rm /etc/kubernetes/pki/apiserver.*

# 重新生成证书（包含 controlPlaneEndpoint）
kubeadm init phase certs apiserver --control-plane-endpoint 192.168.0.40:6443

# 查看apiserver的容器ID，删除进行重启
crictl ps --name kube-apiserver
CONTAINER           IMAGE               CREATED             STATE               NAME                ATTEMPT             POD ID              POD
47bc8e8ffbe34       bdc2eadbf3662       5 hours ago         Running             kube-apiserver      11                  46fe167c5b5fe       kube-apiserver-k8s-master

#删除运行api-server的pod
[root@K8S-Master examples]# sudo crictl rm -f 47bc8e8ffbe34
47bc8e8ffbe34
47bc8e8ffbe34

# 重新创建kube-apiserver
systemctl restart kubelet
```



